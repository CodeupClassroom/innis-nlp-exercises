{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e686dba8",
   "metadata": {},
   "source": [
    "# Parsing Text (aka Prepping Text Data)\n",
    "In this lesson we'll take our acquired data and parse it, that is, we'll better understand the text data by *breaking it down into smaller components.\n",
    "\n",
    "We'll be using the `nltk` package, which requires a little bit of up-front setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6790bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need to install nltk, it should come with anaconda, but nltk needs to download data.\n",
    "# python -c \"import nltk; nltk.download('stopwords')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514d82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unicode, regex, json for text digestion\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "# nltk: natural language toolkit -> tokenization, stopwords (more on this soon)\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# pandas dataframe manipulation, acquire script, time formatting\n",
    "import pandas as pd\n",
    "import acquire\n",
    "from time import strftime\n",
    "\n",
    "# shh, down in front\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79403204",
   "metadata": {},
   "source": [
    "Here's our plan for parsing the text data:\n",
    "\n",
    "1. Convert text to all lower case for normalcy.\n",
    "1. Remove any accented characters, non-ASCII characters.\n",
    "1. Remove special characters.\n",
    "1. Tokenize the words.\n",
    "1. Stem or lemmatize the words.\n",
    "1. Remove stopwords.\n",
    "1. Store the clean text and the original text for use in future notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d89b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = '''\n",
    "What are the Math and Stats Principles You Need for Data Science?Oct 21, 2020 | Data Science\n",
    "\n",
    "\n",
    "Coming into our Data Science program, you will need to know some math and stats. However, many of our applicants actually learn in the application process – you don’t need to be an expert before applying! Data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. But what “skills” do we mean, exactly? Just what exactly are the data science math and stats principles you need to know?\n",
    "What are the main math principles you need to know to get into Codeup’s Data Science program?\n",
    "\n",
    "\n",
    "Algebra\n",
    "Do you know PEMDAS and can you solve for x? You will need to be or become comfortable with the following:\n",
    "\n",
    "Variables (x, y, n, etc.)\n",
    "Formulas, functions, and variable manipulations (e.g. x^2 = x + 6, solve for x).\n",
    "Order of evaluation: PEMDAS: parentheses, exponents, then multiplication, division, addition, and subtraction\n",
    "Commutativity where a + b = b + a\n",
    "Associativity where a + (b + c) = (a + b) + c\n",
    "Adding and subtracting matrices\n",
    "A conceptual understanding of exponential growth/decay- things can increase at an increasing rate\n",
    "\n",
    "Descriptive Statistics\n",
    "Know what a min, max, mode, median, and average are. Have a conceptual understanding that stats/probability is about trying to quantify uncertainty.\n",
    "Data Visualization\n",
    "Know what a scatterplot is and how to read a barplot.\n",
    "How to Learn and Expand on These Concepts\n",
    "There are a number of great resources out there to teach you these and similar concepts. Khan Academy is a great starting place for data science math! If you want to know what exactly we assign our applicants, you’ll just have to apply!\n",
    " \n",
    "What about once you’re in Codeup?\n",
    "\n",
    "\n",
    "What You Won’t Do\n",
    "Do we do any mathematical proofs for concepts or perform derivations? No. \n",
    "Do we do any calculus and probability calculating by hand? No.\n",
    "Are we transforming equations, where we cancel out units or terms and do lots of algebraic gymnastics? No\n",
    "What You Will Do\n",
    "Will we have Python solve our linear algebra problems for us? Yes\n",
    "Will we have Python calculate probabilities, the area under a curve, and the slope of a line for us? Yes\n",
    "Will we have Python do all of the calculus for us? Yes\n",
    " \n",
    "See, the data science math and stats slice of the pie is certainly doable. If you like problem-solving and are ready to challenge yourself, you’ll love data science! If you are interested in learning about data science, just apply! Our Admissions Manager can work with you to get you where you need to be starting from where you are now. Let us help you get there so you can launch a great new career.\n",
    "\n",
    "Request More Info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Our ProgramsFull Stack Web Development\n",
    "Data Science\n",
    "Cyber Cloud\n",
    "Systems Engineering\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Latest Blog Articles\n",
    "Codeup Dallas Open House\n",
    "Codeup’s Placement Team Continues Setting Records\n",
    "IT Certifications 101: Why They Matter, and Why They Don’t\n",
    "A rise in cyber attacks means opportunities for veterans in San Antonio\n",
    "Use your GI Bill® benefits to Land a Job in Tech\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "More From This Category\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Codeup Dallas Open House\n",
    "Nov 30, 2021 | Dallas Newsletter, EventsCome join us for the re-opening of our Dallas Campus with some drinks and snacks at Codeup! Curious about what our campus looks like? Click here to register for free About this event Come join us for the re-opening of our Dallas Campus with some drinks and snacks at...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Codeup’s Placement Team Continues Setting Records\n",
    "Nov 19, 2021 | Codeup News, EmployersOur Placement Team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired. Last quarter the Placement Team helped 48 students get hired to life-changing careers in tech....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IT Certifications 101: Why They Matter, and Why They Don’t\n",
    "Nov 18, 2021 | Cybersecurity, IT Training, Tips for Prospective StudentsAWS, Google, Azure, Red Hat, CompTIA...these are big names in IT! And not only for their products, but also for the certifications they offer. If you’re new to tech, you might be wondering: Do certifications really matter? Welcome to IT Certifications 101! What’s the...\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af060646",
   "metadata": {},
   "source": [
    "#### Step 1: Convert all text to lower for normalcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cfe192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what are the math and stats principles you need for data science?oct 21, 2020 | data science\n",
      "\n",
      "\n",
      "coming into our data science program, you will need to know some math and stats. however, many of our applicants actually learn in the application process – you don’t need to be an expert before applying! data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. but what “skills” do we mean, exactly? just what exactly are the data science math and stats principles you need to know?\n",
      "what are the main math principles you need to know to get into codeup’s data science program?\n",
      "\n",
      "\n",
      "algebra\n",
      "do you know pemdas and can you solve for x? you will need to be or become comfortable with the following:\n",
      "\n",
      "variables (x, y, n, etc.)\n",
      "formulas, functions, and variable manipulations (e.g. x^2 = x + 6, solve for x).\n",
      "order of evaluation: pemdas: parentheses, exponents, then multiplication, division, addition, and subtraction\n",
      "commutativity where a + b = b + a\n",
      "associativity where a + (b + c) = (a + b) + c\n",
      "adding and subtracting matrices\n",
      "a conceptual understanding of exponential growth/decay- things can increase at an increasing rate\n",
      "\n",
      "descriptive statistics\n",
      "know what a min, max, mode, median, and average are. have a conceptual understanding that stats/probability is about trying to quantify uncertainty.\n",
      "data visualization\n",
      "know what a scatterplot is and how to read a barplot.\n",
      "how to learn and expand on these concepts\n",
      "there are a number of great resources out there to teach you these and similar concepts. khan academy is a great starting place for data science math! if you want to know what exactly we assign our applicants, you’ll just have to apply!\n",
      " \n",
      "what about once you’re in codeup?\n",
      "\n",
      "\n",
      "what you won’t do\n",
      "do we do any mathematical proofs for concepts or perform derivations? no. \n",
      "do we do any calculus and probability calculating by hand? no.\n",
      "are we transforming equations, where we cancel out units or terms and do lots of algebraic gymnastics? no\n",
      "what you will do\n",
      "will we have python solve our linear algebra problems for us? yes\n",
      "will we have python calculate probabilities, the area under a curve, and the slope of a line for us? yes\n",
      "will we have python do all of the calculus for us? yes\n",
      " \n",
      "see, the data science math and stats slice of the pie is certainly doable. if you like problem-solving and are ready to challenge yourself, you’ll love data science! if you are interested in learning about data science, just apply! our admissions manager can work with you to get you where you need to be starting from where you are now. let us help you get there so you can launch a great new career.\n",
      "\n",
      "request more info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our programsfull stack web development\n",
      "data science\n",
      "cyber cloud\n",
      "systems engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "latest blog articles\n",
      "codeup dallas open house\n",
      "codeup’s placement team continues setting records\n",
      "it certifications 101: why they matter, and why they don’t\n",
      "a rise in cyber attacks means opportunities for veterans in san antonio\n",
      "use your gi bill® benefits to land a job in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "more from this category\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup dallas open house\n",
      "nov 30, 2021 | dallas newsletter, eventscome join us for the re-opening of our dallas campus with some drinks and snacks at codeup! curious about what our campus looks like? click here to register for free about this event come join us for the re-opening of our dallas campus with some drinks and snacks at...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup’s placement team continues setting records\n",
      "nov 19, 2021 | codeup news, employersour placement team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired. last quarter the placement team helped 48 students get hired to life-changing careers in tech....\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it certifications 101: why they matter, and why they don’t\n",
      "nov 18, 2021 | cybersecurity, it training, tips for prospective studentsaws, google, azure, red hat, comptia...these are big names in it! and not only for their products, but also for the certifications they offer. if you’re new to tech, you might be wondering: do certifications really matter? welcome to it certifications 101! what’s the...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = original.lower()\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e3823",
   "metadata": {},
   "source": [
    "#### Step 2: Remove any accented characters, non-ASCII characters.\n",
    "\n",
    "Usually in any text corpus, you might be dealing with accented characters/letters, especially if you only want to analyze the English language. Hence, we need to make sure that these characters are converted and standardized into ASCII characters. A simple example is converting é to e.\n",
    "\n",
    "We'll go about this in three steps:\n",
    "\n",
    "1. `unicodedata.normalize` removes any inconsistencies in unicode character encoding.\n",
    "1. `.encode` to convert the resulting string to the ASCII character set. We'll ignore any errors in conversion, meaning we'll drop anything that isn't an ASCII character.\n",
    "1. `.decode` to turn the resulting bytes object back into a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e0522-f4c1-4383-8c73-6dd471d97fb6",
   "metadata": {},
   "source": [
    "ℌ ̧ ==> H ̧ ==> Ḩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228c3ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what are the math and stats principles you need for data science?oct 21, 2020 | data science\n",
      "\n",
      "\n",
      "coming into our data science program, you will need to know some math and stats. however, many of our applicants actually learn in the application process  you dont need to be an expert before applying! data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. but what skills do we mean, exactly? just what exactly are the data science math and stats principles you need to know?\n",
      "what are the main math principles you need to know to get into codeups data science program?\n",
      "\n",
      "\n",
      "algebra\n",
      "do you know pemdas and can you solve for x? you will need to be or become comfortable with the following:\n",
      "\n",
      "variables (x, y, n, etc.)\n",
      "formulas, functions, and variable manipulations (e.g. x^2 = x + 6, solve for x).\n",
      "order of evaluation: pemdas: parentheses, exponents, then multiplication, division, addition, and subtraction\n",
      "commutativity where a + b = b + a\n",
      "associativity where a + (b + c) = (a + b) + c\n",
      "adding and subtracting matrices\n",
      "a conceptual understanding of exponential growth/decay- things can increase at an increasing rate\n",
      "\n",
      "descriptive statistics\n",
      "know what a min, max, mode, median, and average are. have a conceptual understanding that stats/probability is about trying to quantify uncertainty.\n",
      "data visualization\n",
      "know what a scatterplot is and how to read a barplot.\n",
      "how to learn and expand on these concepts\n",
      "there are a number of great resources out there to teach you these and similar concepts. khan academy is a great starting place for data science math! if you want to know what exactly we assign our applicants, youll just have to apply!\n",
      " \n",
      "what about once youre in codeup?\n",
      "\n",
      "\n",
      "what you wont do\n",
      "do we do any mathematical proofs for concepts or perform derivations? no. \n",
      "do we do any calculus and probability calculating by hand? no.\n",
      "are we transforming equations, where we cancel out units or terms and do lots of algebraic gymnastics? no\n",
      "what you will do\n",
      "will we have python solve our linear algebra problems for us? yes\n",
      "will we have python calculate probabilities, the area under a curve, and the slope of a line for us? yes\n",
      "will we have python do all of the calculus for us? yes\n",
      " \n",
      "see, the data science math and stats slice of the pie is certainly doable. if you like problem-solving and are ready to challenge yourself, youll love data science! if you are interested in learning about data science, just apply! our admissions manager can work with you to get you where you need to be starting from where you are now. let us help you get there so you can launch a great new career.\n",
      "\n",
      "request more info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our programsfull stack web development\n",
      "data science\n",
      "cyber cloud\n",
      "systems engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "latest blog articles\n",
      "codeup dallas open house\n",
      "codeups placement team continues setting records\n",
      "it certifications 101: why they matter, and why they dont\n",
      "a rise in cyber attacks means opportunities for veterans in san antonio\n",
      "use your gi bill benefits to land a job in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "more from this category\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup dallas open house\n",
      "nov 30, 2021 | dallas newsletter, eventscome join us for the re-opening of our dallas campus with some drinks and snacks at codeup! curious about what our campus looks like? click here to register for free about this event come join us for the re-opening of our dallas campus with some drinks and snacks at...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeups placement team continues setting records\n",
      "nov 19, 2021 | codeup news, employersour placement team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired. last quarter the placement team helped 48 students get hired to life-changing careers in tech....\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it certifications 101: why they matter, and why they dont\n",
      "nov 18, 2021 | cybersecurity, it training, tips for prospective studentsaws, google, azure, red hat, comptia...these are big names in it! and not only for their products, but also for the certifications they offer. if youre new to tech, you might be wondering: do certifications really matter? welcome to it certifications 101! whats the...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496ecea",
   "metadata": {},
   "source": [
    "#### Step 3: Remove special characters\n",
    "\n",
    "Special characters and symbols are usually non-alphanumeric characters or even occasionally numeric characters (depending on the problem), which add to the extra noise in unstructured text. Usually, simple regular expressions (regexes) can be used to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e886940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what are the math and stats principles you need for data scienceoct 21 2020  data science\n",
      "\n",
      "\n",
      "coming into our data science program you will need to know some math and stats however many of our applicants actually learn in the application process  you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skills and we can work with any applicant to help them learn what they need to know but what skills do we mean exactly just what exactly are the data science math and stats principles you need to know\n",
      "what are the main math principles you need to know to get into codeups data science program\n",
      "\n",
      "\n",
      "algebra\n",
      "do you know pemdas and can you solve for x you will need to be or become comfortable with the following\n",
      "\n",
      "variables x y n etc\n",
      "formulas functions and variable manipulations eg x2  x  6 solve for x\n",
      "order of evaluation pemdas parentheses exponents then multiplication division addition and subtraction\n",
      "commutativity where a  b  b  a\n",
      "associativity where a  b  c  a  b  c\n",
      "adding and subtracting matrices\n",
      "a conceptual understanding of exponential growthdecay things can increase at an increasing rate\n",
      "\n",
      "descriptive statistics\n",
      "know what a min max mode median and average are have a conceptual understanding that statsprobability is about trying to quantify uncertainty\n",
      "data visualization\n",
      "know what a scatterplot is and how to read a barplot\n",
      "how to learn and expand on these concepts\n",
      "there are a number of great resources out there to teach you these and similar concepts khan academy is a great starting place for data science math if you want to know what exactly we assign our applicants youll just have to apply\n",
      " \n",
      "what about once youre in codeup\n",
      "\n",
      "\n",
      "what you wont do\n",
      "do we do any mathematical proofs for concepts or perform derivations no \n",
      "do we do any calculus and probability calculating by hand no\n",
      "are we transforming equations where we cancel out units or terms and do lots of algebraic gymnastics no\n",
      "what you will do\n",
      "will we have python solve our linear algebra problems for us yes\n",
      "will we have python calculate probabilities the area under a curve and the slope of a line for us yes\n",
      "will we have python do all of the calculus for us yes\n",
      " \n",
      "see the data science math and stats slice of the pie is certainly doable if you like problemsolving and are ready to challenge yourself youll love data science if you are interested in learning about data science just apply our admissions manager can work with you to get you where you need to be starting from where you are now let us help you get there so you can launch a great new career\n",
      "\n",
      "request more info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our programsfull stack web development\n",
      "data science\n",
      "cyber cloud\n",
      "systems engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "latest blog articles\n",
      "codeup dallas open house\n",
      "codeups placement team continues setting records\n",
      "it certifications 101 why they matter and why they dont\n",
      "a rise in cyber attacks means opportunities for veterans in san antonio\n",
      "use your gi bill benefits to land a job in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "more from this category\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup dallas open house\n",
      "nov 30 2021  dallas newsletter eventscome join us for the reopening of our dallas campus with some drinks and snacks at codeup curious about what our campus looks like click here to register for free about this event come join us for the reopening of our dallas campus with some drinks and snacks at\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeups placement team continues setting records\n",
      "nov 19 2021  codeup news employersour placement team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired last quarter the placement team helped 48 students get hired to lifechanging careers in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it certifications 101 why they matter and why they dont\n",
      "nov 18 2021  cybersecurity it training tips for prospective studentsaws google azure red hat comptiathese are big names in it and not only for their products but also for the certifications they offer if youre new to tech you might be wondering do certifications really matter welcome to it certifications 101 whats the\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove anything that is not a through z, a number, a single quote, or whitespace\n",
    "article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "print(article)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d33fac4",
   "metadata": {},
   "source": [
    "#### Step 4: Tokenization\n",
    "\n",
    "After removing non-ASCII characters and special characters, it's common to tokenize the strings, to break words and any punctuation left over into discrete units. Tokenization is the process of breaking something down into discrete units. In the context of NLP, this means breaking text down into discrete words, punctuation, etc.\n",
    "\n",
    "We will use `nltk` to do tokenization for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33271c9c-1fd4-42c4-a2fd-4e3a80bfa577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a string that we might ' ve tokenized\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"Here is a string that we might've tokenized\", return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e4d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the Math and Stats Principles You Need for Data Science?Oct 21 , 2020 &#124; Data Science\n",
      "\n",
      "\n",
      "Coming into our Data Science program , you will need to know some math and stats. However , many of our applicants actually learn in the application process – you don ’ t need to be an expert before applying ! Data science is a very accessible field to anyone dedicated to learning new skills , and we can work with any applicant to help them learn what they need to know. But what “skills ” do we mean , exactly ? Just what exactly are the data science math and stats principles you need to know ? \n",
      "What are the main math principles you need to know to get into Codeup ’ s Data Science program ? \n",
      "\n",
      "\n",
      "Algebra\n",
      "Do you know PEMDAS and can you solve for x ? You will need to be or become comfortable with the following : \n",
      "\n",
      "Variables ( x , y , n , etc. ) \n",
      "Formulas , functions , and variable manipulations ( e.g. x^2 = x + 6 , solve for x ) .\n",
      "Order of evaluation : PEMDAS : parentheses , exponents , then multiplication , division , addition , and subtraction\n",
      "Commutativity where a + b = b + a\n",
      "Associativity where a + ( b + c ) = ( a + b ) + c\n",
      "Adding and subtracting matrices\n",
      "A conceptual understanding of exponential growth/decay- things can increase at an increasing rate\n",
      "\n",
      "Descriptive Statistics\n",
      "Know what a min , max , mode , median , and average are. Have a conceptual understanding that stats/probability is about trying to quantify uncertainty.\n",
      "Data Visualization\n",
      "Know what a scatterplot is and how to read a barplot.\n",
      "How to Learn and Expand on These Concepts\n",
      "There are a number of great resources out there to teach you these and similar concepts. Khan Academy is a great starting place for data science math ! If you want to know what exactly we assign our applicants , you ’ ll just have to apply ! \n",
      " \n",
      "What about once you ’ re in Codeup ? \n",
      "\n",
      "\n",
      "What You Won ’ t Do\n",
      "Do we do any mathematical proofs for concepts or perform derivations ? No. \n",
      "Do we do any calculus and probability calculating by hand ? No.\n",
      "Are we transforming equations , where we cancel out units or terms and do lots of algebraic gymnastics ? No\n",
      "What You Will Do\n",
      "Will we have Python solve our linear algebra problems for us ? Yes\n",
      "Will we have Python calculate probabilities , the area under a curve , and the slope of a line for us ? Yes\n",
      "Will we have Python do all of the calculus for us ? Yes\n",
      " \n",
      "See , the data science math and stats slice of the pie is certainly doable. If you like problem-solving and are ready to challenge yourself , you ’ ll love data science ! If you are interested in learning about data science , just apply ! Our Admissions Manager can work with you to get you where you need to be starting from where you are now. Let us help you get there so you can launch a great new career.\n",
      "\n",
      "Request More Info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Our ProgramsFull Stack Web Development\n",
      "Data Science\n",
      "Cyber Cloud\n",
      "Systems Engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Latest Blog Articles\n",
      "Codeup Dallas Open House\n",
      "Codeup ’ s Placement Team Continues Setting Records\n",
      "IT Certifications 101 : Why They Matter , and Why They Don ’ t\n",
      "A rise in cyber attacks means opportunities for veterans in San Antonio\n",
      "Use your GI Bill ® benefits to Land a Job in Tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "More From This Category\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Codeup Dallas Open House\n",
      "Nov 30 , 2021 &#124; Dallas Newsletter , EventsCome join us for the re-opening of our Dallas Campus with some drinks and snacks at Codeup ! Curious about what our campus looks like ? Click here to register for free About this event Come join us for the re-opening of our Dallas Campus with some drinks and snacks at ... \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Codeup ’ s Placement Team Continues Setting Records\n",
      "Nov 19 , 2021 &#124; Codeup News , EmployersOur Placement Team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired. Last quarter the Placement Team helped 48 students get hired to life-changing careers in tech .... \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "IT Certifications 101 : Why They Matter , and Why They Don ’ t\n",
      "Nov 18 , 2021 &#124; Cybersecurity , IT Training , Tips for Prospective StudentsAWS , Google , Azure , Red Hat , CompTIA ... these are big names in IT ! And not only for their products , but also for the certifications they offer. If you ’ re new to tech , you might be wondering : Do certifications really matter ? Welcome to IT Certifications 101 ! What ’ s the ...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(original, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89f6a4",
   "metadata": {},
   "source": [
    "#### Step 5: Stemming and Lemmatization\n",
    "\n",
    "Usually you will want to use lemmatization. We will demonstrate why that is the case by looking at both here.\n",
    "\n",
    "#### Stemming:\n",
    "Word stems are the base form of a word.\n",
    "\n",
    "We create new words by attaching affixes in a process known as inflection. For example, \"calls\", \"called\", and \"calling\" all share the base stem \"call\".\n",
    "\n",
    "The Porter stemmer is based on the algorithm developed by its inventor, Dr. Martin Porter. Originally, the algorithm is said to have had a total of five different phases for reduction of inflections to their stems, where each phase has its own set of rules.\n",
    "\n",
    "Note that usually stemming has a fixed set of rules, hence, the root stems may not be lexicographically correct. This means that the stemmed words may not be semantically correct, and might have a chance of not being present in the dictionary (as we'll see in the output of stemming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02349d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the nltk stemmer object, then use it\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "ps.stem('call'), ps.stem('calling'), ps.stem('called')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0849fe",
   "metadata": {},
   "source": [
    "Now we can apply this stemming transformation to all the words in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1abc48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stat principl you need for data scienceoct 21 2020 data scienc come into our data scienc program you will need to know some math and stat howev mani of our applic actual learn in the applic process you dont need to be an expert befor appli data scienc is a veri access field to anyon dedic to learn new skill and we can work with ani applic to help them learn what they need to know but what skill do we mean exactli just what exactli are the data scienc math and stat principl you need to know what are the main math principl you need to know to get into codeup data scienc program algebra do you know pemda and can you solv for x you will need to be or becom comfort with the follow variabl x y n etc formula function and variabl manipul eg x2 x 6 solv for x order of evalu pemda parenthes expon then multipl divis addit and subtract commut where a b b a associ where a b c a b c ad and subtract matric a conceptu understand of exponenti growthdecay thing can increas at an increas rate descript statist know what a min max mode median and averag are have a conceptu understand that statsprob is about tri to quantifi uncertainti data visual know what a scatterplot is and how to read a barplot how to learn and expand on these concept there are a number of great resourc out there to teach you these and similar concept khan academi is a great start place for data scienc math if you want to know what exactli we assign our applic youll just have to appli what about onc your in codeup what you wont do do we do ani mathemat proof for concept or perform deriv no do we do ani calculu and probabl calcul by hand no are we transform equat where we cancel out unit or term and do lot of algebra gymnast no what you will do will we have python solv our linear algebra problem for us ye will we have python calcul probabl the area under a curv and the slope of a line for us ye will we have python do all of the calculu for us ye see the data scienc math and stat slice of the pie is certainli doabl if you like problemsolv and are readi to challeng yourself youll love data scienc if you are interest in learn about data scienc just appli our admiss manag can work with you to get you where you need to be start from where you are now let us help you get there so you can launch a great new career request more info our programsful stack web develop data scienc cyber cloud system engin latest blog articl codeup dalla open hous codeup placement team continu set record it certif 101 whi they matter and whi they dont a rise in cyber attack mean opportun for veteran in san antonio use your gi bill benefit to land a job in tech more from thi categori codeup dalla open hous nov 30 2021 dalla newslett eventscom join us for the reopen of our dalla campu with some drink and snack at codeup curiou about what our campu look like click here to regist for free about thi event come join us for the reopen of our dalla campu with some drink and snack at codeup placement team continu set record nov 19 2021 codeup news employersour placement team is simpli defin as a group that manag relationship with our employ partner and our graduat student to help get our graduat student hire last quarter the placement team help 48 student get hire to lifechang career in tech it certif 101 whi they matter and whi they dont nov 18 2021 cybersecur it train tip for prospect studentsaw googl azur red hat comptiathes are big name in it and not onli for their product but also for the certif they offer if your new to tech you might be wonder do certif realli matter welcom to it certif 101 what the\n"
     ]
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in article.split()]\n",
    "article_stemmed = ' '.join(stems)\n",
    "print(article_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6383f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to     25\n",
       "and    23\n",
       "you    21\n",
       "a      18\n",
       "the    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(stems).value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b51168",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "Lemmatization is very similar to stemming, however, the base form in this case is known as the root word, but not the root stem. The difference is that the root word is always a lexicographically correct word (present in the dictionary), but the root stem may not be so. Thus, root word, also known as the lemma, will always be present in the dictionary.\n",
    "\n",
    "Note that the lemmatization process is considerably slower than stemming, because an additional step is involved where the root form or lemma is formed by removing the affix from the word if and only if the lemma is present in the dictionary.\n",
    "\n",
    "Let's take a look at a simple example of the difference between stemming and lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -c \"import nltk; nltk.download('all')\"\n",
    "# OR\n",
    "# python3 -c \"import nltk; nltk.download('wordnet')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc277fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma:  would ------ stem:  would\n",
      "lemma:  ' ------ stem:  '\n",
      "lemma:  ve ------ stem:  ve\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for word in \"would ' ve\".split():\n",
    "    print('lemma: ', wnl.lemmatize(word), '------ stem: ', ps.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b065a5c3",
   "metadata": {},
   "source": [
    "And now we can apply lemmatization to our entire document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7112e41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stats principle you need for data scienceoct 21 2020 data science coming into our data science program you will need to know some math and stats however many of our applicant actually learn in the application process you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skill and we can work with any applicant to help them learn what they need to know but what skill do we mean exactly just what exactly are the data science math and stats principle you need to know what are the main math principle you need to know to get into codeups data science program algebra do you know pemdas and can you solve for x you will need to be or become comfortable with the following variable x y n etc formula function and variable manipulation eg x2 x 6 solve for x order of evaluation pemdas parenthesis exponent then multiplication division addition and subtraction commutativity where a b b a associativity where a b c a b c adding and subtracting matrix a conceptual understanding of exponential growthdecay thing can increase at an increasing rate descriptive statistic know what a min max mode median and average are have a conceptual understanding that statsprobability is about trying to quantify uncertainty data visualization know what a scatterplot is and how to read a barplot how to learn and expand on these concept there are a number of great resource out there to teach you these and similar concept khan academy is a great starting place for data science math if you want to know what exactly we assign our applicant youll just have to apply what about once youre in codeup what you wont do do we do any mathematical proof for concept or perform derivation no do we do any calculus and probability calculating by hand no are we transforming equation where we cancel out unit or term and do lot of algebraic gymnastics no what you will do will we have python solve our linear algebra problem for u yes will we have python calculate probability the area under a curve and the slope of a line for u yes will we have python do all of the calculus for u yes see the data science math and stats slice of the pie is certainly doable if you like problemsolving and are ready to challenge yourself youll love data science if you are interested in learning about data science just apply our admission manager can work with you to get you where you need to be starting from where you are now let u help you get there so you can launch a great new career request more info our programsfull stack web development data science cyber cloud system engineering latest blog article codeup dallas open house codeups placement team continues setting record it certification 101 why they matter and why they dont a rise in cyber attack mean opportunity for veteran in san antonio use your gi bill benefit to land a job in tech more from this category codeup dallas open house nov 30 2021 dallas newsletter eventscome join u for the reopening of our dallas campus with some drink and snack at codeup curious about what our campus look like click here to register for free about this event come join u for the reopening of our dallas campus with some drink and snack at codeups placement team continues setting record nov 19 2021 codeup news employersour placement team is simply defined a a group that manages relationship with our employer partner and our graduating student to help get our graduating student hired last quarter the placement team helped 48 student get hired to lifechanging career in tech it certification 101 why they matter and why they dont nov 18 2021 cybersecurity it training tip for prospective studentsaws google azure red hat comptiathese are big name in it and not only for their product but also for the certification they offer if youre new to tech you might be wondering do certification really matter welcome to it certification 101 whats the\n"
     ]
    }
   ],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "article_lemmatized = ' '.join(lemmas)\n",
    "\n",
    "print(article_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3df52",
   "metadata": {},
   "source": [
    "Now that we have a list of the lemmas, we can take a look at the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee698345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to     25\n",
       "and    23\n",
       "you    21\n",
       "a      19\n",
       "the    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lemmas).value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98721359",
   "metadata": {},
   "source": [
    "#### Step 6: Removing stopwords\n",
    "\n",
    "Words which have little or no significance, especially when constructing meaningful features from text, are known as stop words (or stopwords). These are usually words that end up having the maximum frequency if you do a simple term or word frequency in a corpus. Typically, these can be articles, conjunctions, prepositions and so on. Some examples of stopwords: a, an, the, and like.\n",
    "\n",
    "While there is no universal stopword list, we will use a standard English language stopwords list from nltk. You can also add your own domain-specific stopwords as needed.\n",
    "\n",
    "Before removing stopwords, we want to segment text into linguistic units such as words or numbers. This process is called tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95e55a85-83cb-413c-8b20-6f14f6496010",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99a9daa9-cd13-4cdc-8e4c-0af3aea64a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d5a1c-708b-4699-b20a-5c3bfc051c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2378689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae007363-980e-46f8-ada4-7029925c557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list.remove('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d48ec681-a4c6-49d3-acfb-a8a266a8b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caec6f5b-659d-4357-b331-d773b277b805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e81f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 307 stopwords\n",
      "---\n",
      "math stats principles need data scienceoct 21 2020 data science coming data science program need know math stats however many applicants actually learn application process dont need expert applying data science accessible field anyone dedicated learning new skills work applicant help learn need know skills mean exactly exactly data science math stats principles need know main math principles need know get codeups data science program algebra know pemdas solve x need become comfortable following variables x n etc formulas functions variable manipulations eg x2 x 6 solve x order evaluation pemdas parentheses exponents multiplication division addition subtraction commutativity b b associativity b c b c adding subtracting matrices conceptual understanding exponential growthdecay things increase increasing rate descriptive statistics know min max mode median average conceptual understanding statsprobability trying quantify uncertainty data visualization know scatterplot read barplot learn expand concepts number great resources teach similar concepts khan academy great starting place data science math want know exactly assign applicants youll apply youre codeup wont mathematical proofs concepts perform derivations no calculus probability calculating hand no transforming equations cancel units terms lots algebraic gymnastics no python solve linear algebra problems us yes python calculate probabilities area curve slope line us yes python calculus us yes see data science math stats slice pie certainly doable like problemsolving ready challenge youll love data science interested learning data science apply admissions manager work get need starting let us help get launch great new career request info programsfull stack web development data science cyber cloud systems engineering latest blog articles codeup dallas open house codeups placement team continues setting records certifications 101 matter dont rise cyber attacks means opportunities veterans san antonio use gi bill benefits land job tech category codeup dallas open house nov 30 2021 dallas newsletter eventscome join us reopening dallas campus drinks snacks codeup curious campus looks like click register free event come join us reopening dallas campus drinks snacks codeups placement team continues setting records nov 19 2021 codeup news employersour placement team simply defined group manages relationships employer partners graduating students help get graduating students hired last quarter placement team helped 48 students get hired lifechanging careers tech certifications 101 matter dont nov 18 2021 cybersecurity training tips prospective studentsaws google azure red hat comptiathese big names not products also certifications offer youre new tech might wondering certifications really matter welcome certifications 101 whats\n"
     ]
    }
   ],
   "source": [
    "words = article.split()\n",
    "filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "print('---')\n",
    "\n",
    "article_without_stopwords = ' '.join(filtered_words)\n",
    "\n",
    "print(article_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "929ae3b8-aebd-444e-8bca-aed58ef8c7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data       12\n",
       "science    10\n",
       "need        8\n",
       "know        8\n",
       "us          6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(filtered_words).value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685f215-7b4e-4f0e-a9b2-7b4a80df0b54",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "The end result of this exercise should be a file named `prepare.py` that defines the requested functions.\n",
    "\n",
    "In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired.\n",
    "\n",
    "1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc4c7d21-33e5-49ee-bc82-17a9815e68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will define a basic_clean function for a single document (one string)\n",
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    # we will normalize our data into standard NFKD unicode, feed it into an ascii encoding\n",
    "    # decode it back into UTF-8\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    # utilize our regex substitution to remove our undesirable characters, then lowercase\n",
    "    string = re.sub(r\"[^\\w0-9'\\s]\", '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e43c6-3249-41ff-a11c-69ffc0981f69",
   "metadata": {},
   "source": [
    "2. Define a function named `tokenize`. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65d9d1df-b305-4ab7-a262-f100b9a11194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # make our tokenizer, taken from nltk's ToktokTokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # apply our tokenizer's tokenization to the string being input, ensure it returns a string\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c2909-8a7d-4504-bcac-ddc6dbf9ad55",
   "metadata": {},
   "source": [
    "3. Define a function named `stem`. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bb41818-36ff-4275-9f5d-8d1b39f1d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # create our stemming object\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # use a list comprehension => stem each word for each word inside of the entire document,\n",
    "    # split by the default, which are single spaces\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    # glue it back together with spaces, as it was before\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48662ff-0ab3-45e5-b7bd-ceeeaadf6138",
   "metadata": {},
   "source": [
    "4. Define a function named `lemmatize`. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59c16870-544c-4041-bd40-8045f595bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # create our lemmatizer object\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    # use a list comprehension to lemmatize each word\n",
    "    # string.split() => output a list of every token inside of the document\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    # glue the lemmas back together by the strings we split on\n",
    "    string = ' '.join(lemmas)\n",
    "    #return the altered document\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2f6e8-3179-4887-8996-51e3cbc0fdd6",
   "metadata": {},
   "source": [
    "5. Define a function named `remove_stopwords`. It should accept some text and return the text after removing all the stopwords.     This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffe3a6af-2697-48ec-b80a-e95fd4dc8d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "list1 = [1, 2, 3, 4]\n",
    "list2 = [2, 1, 3, 4]\n",
    "\n",
    "print(set(list1)==set(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da61b1dd-2b4c-4814-913b-68aad2abc015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'c', 'd'] {'b', 'c', 'd', 'a'}\n"
     ]
    }
   ],
   "source": [
    "mylist = ['a', 'b', 'c', 'c', 'd']\n",
    "\n",
    "myset = set(mylist)\n",
    "\n",
    "print(mylist, myset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a81a6cc5-6fe2-48a5-a45d-a8ade83a5c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab3e6359-b254-4d44-a9b4-9d537493fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # assign our stopwords from nltk into stopword_list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # utilizing set casting, i will remove any excluded stopwords\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    # add in any extra words to my stopwords set using a union\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    # split our document by spaces\n",
    "    words = string.split()\n",
    "    # every word in our document, as long as that word is not in our stopwords\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    # glue it back together with spaces, as it was so it shall be\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    # return the document back\n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ee8ac-d42f-4496-ab85-e25999c501c8",
   "metadata": {},
   "source": [
    "6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe `news_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c73c4f0-fc68-40ae-811e-b38c082e1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_all_new_article function from acquire.py file \n",
    "news_df = acquire.get_news_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a9f9c4-2bf2-4200-bab2-27dae4282798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Rupee hits all-time low of 77.42 against US do...</td>\n",
       "      <td>The Indian rupee fell to an all-time low of 77...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>2022-05-09T05:05:31.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Bitcoin falls to the lowest level since Januar...</td>\n",
       "      <td>Bitcoin fell on Monday to as low as $33,266 in...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>2022-05-09T09:20:34.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Rupee closes at all-time low of 77.50 against ...</td>\n",
       "      <td>The Indian rupee weakened further on Monday to...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>2022-05-09T15:27:43.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Made best possible decision: IndiGo on barring...</td>\n",
       "      <td>IndiGo's CEO Ronojoy Dutta said the airline ma...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>2022-05-09T09:50:34.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>India's biggest IPO of LIC subscribed nearly 3...</td>\n",
       "      <td>LIC's IPO, India's biggest IPO which opened on...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>2022-05-09T14:10:38.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                              title  \\\n",
       "0  business  Rupee hits all-time low of 77.42 against US do...   \n",
       "1  business  Bitcoin falls to the lowest level since Januar...   \n",
       "2  business  Rupee closes at all-time low of 77.50 against ...   \n",
       "3  business  Made best possible decision: IndiGo on barring...   \n",
       "4  business  India's biggest IPO of LIC subscribed nearly 3...   \n",
       "\n",
       "                                             content          author  \\\n",
       "0  The Indian rupee fell to an all-time low of 77...    Apaar Sharma   \n",
       "1  Bitcoin fell on Monday to as low as $33,266 in...  Pragya Swastik   \n",
       "2  The Indian rupee weakened further on Monday to...  Pragya Swastik   \n",
       "3  IndiGo's CEO Ronojoy Dutta said the airline ma...  Pragya Swastik   \n",
       "4  LIC's IPO, India's biggest IPO which opened on...  Pragya Swastik   \n",
       "\n",
       "                  published  \n",
       "0  2022-05-09T05:05:31.000Z  \n",
       "1  2022-05-09T09:20:34.000Z  \n",
       "2  2022-05-09T15:27:43.000Z  \n",
       "3  2022-05-09T09:50:34.000Z  \n",
       "4  2022-05-09T14:10:38.000Z  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc85734-cb13-447f-93ad-73e431d0f98b",
   "metadata": {},
   "source": [
    "7. Make another dataframe for the Codeup blog posts. Name the dataframe `codeup_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64f8d026-6606-41e7-84ed-5bc9f0806f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = acquire.get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fe276f4-1ed2-43d6-8915-3f57df80e90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learn to Code: Python Workshop on 4/23</td>\n",
       "      <td>Mar 31, 2022</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coming Soon: Cloud Administration</td>\n",
       "      <td>Mar 17, 2022</td>\n",
       "      <td>We’re launching a new program out of San Anton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 Books Every Woman In Tech Should Read</td>\n",
       "      <td>Mar 8, 2022</td>\n",
       "      <td>On this International Women’s Day 2022 we want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     published  \\\n",
       "0             Learn to Code: Python Workshop on 4/23  Mar 31, 2022   \n",
       "1                  Coming Soon: Cloud Administration  Mar 17, 2022   \n",
       "2            5 Books Every Woman In Tech Should Read   Mar 8, 2022   \n",
       "3                  Codeup Start Dates for March 2022  Jan 26, 2022   \n",
       "4  VET TEC Funding Now Available For Dallas Veterans   Jan 7, 2022   \n",
       "\n",
       "                                             content  \n",
       "0  According to LinkedIn, the “#1 Most Promising ...  \n",
       "1  We’re launching a new program out of San Anton...  \n",
       "2  On this International Women’s Day 2022 we want...  \n",
       "3  As we approach the end of January we wanted to...  \n",
       "4  We are so happy to announce that VET TEC benef...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347739f-b59a-497f-82cf-1d86ca94fe0a",
   "metadata": {},
   "source": [
    "8. For each dataframe, produce the following columns:\n",
    "- `title` to hold the title\n",
    "- `original` to hold the original article/post content\n",
    "- `clean` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- `stemmed` to hold the stemmed version of the cleaned data.\n",
    "- `lemmatized` to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17492d27-741a-4966-a7a4-b1c03a539f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we want:\n",
    "#  -clean: normalized/tokenized, with stopwords removed\n",
    "#         apply: basic_clean, tokenize, remove_stopwords\n",
    "#  -stemmed: stemmed version of cleaned data\n",
    "            # apply: stem function onto cleaned data\n",
    "#  -lemmatized: lemmatized version of cleaned data\n",
    "            # apply: lemmatize function onto cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292316a4-90f7-4a4d-b987-a5c34c35be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['some_col'] = df['old_col'].apply(some_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "919646af-d2d1-4dfe-b479-6b274ceb0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.rename(columns={'content': 'original'}, inplace=True)\n",
    "codeup_df.rename(columns={'content': 'original'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e34d1ef-075b-447b-a192-fb8c40dd0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords,\n",
    "                                  extra_words=extra_words,\n",
    "                                  exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df['clean'].apply(stem)\n",
    "    \n",
    "    df['lemmatized'] = df['clean'].apply(lemmatize)\n",
    "    \n",
    "    return df[['title', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2faf956d-dfde-4d72-9b35-af2ae25e4e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rupee hits all-time low of 77.42 against US do...</td>\n",
       "      <td>The Indian rupee fell to an all-time low of 77...</td>\n",
       "      <td>indian rupee fell alltime low 7742 us dollar m...</td>\n",
       "      <td>indian rupe fell alltim low 7742 us dollar mon...</td>\n",
       "      <td>indian rupee fell alltime low 7742 u dollar mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin falls to the lowest level since Januar...</td>\n",
       "      <td>Bitcoin fell on Monday to as low as $33,266 in...</td>\n",
       "      <td>bitcoin fell monday low 33266 morning trade ne...</td>\n",
       "      <td>bitcoin fell monday low 33266 morn trade near ...</td>\n",
       "      <td>bitcoin fell monday low 33266 morning trade ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee closes at all-time low of 77.50 against ...</td>\n",
       "      <td>The Indian rupee weakened further on Monday to...</td>\n",
       "      <td>indian rupee weakened monday close new alltime...</td>\n",
       "      <td>indian rupe weaken monday close new alltim low...</td>\n",
       "      <td>indian rupee weakened monday close new alltime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Made best possible decision: IndiGo on barring...</td>\n",
       "      <td>IndiGo's CEO Ronojoy Dutta said the airline ma...</td>\n",
       "      <td>indigos ceo ronojoy dutta said airline made be...</td>\n",
       "      <td>indigo ceo ronojoy dutta said airlin made best...</td>\n",
       "      <td>indigo ceo ronojoy dutta said airline made bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India's biggest IPO of LIC subscribed nearly 3...</td>\n",
       "      <td>LIC's IPO, India's biggest IPO which opened on...</td>\n",
       "      <td>lics ipo indias biggest ipo opened may 4 close...</td>\n",
       "      <td>lic ipo india biggest ipo open may 4 close may...</td>\n",
       "      <td>lics ipo india biggest ipo opened may 4 closed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Rupee hits all-time low of 77.42 against US do...   \n",
       "1  Bitcoin falls to the lowest level since Januar...   \n",
       "2  Rupee closes at all-time low of 77.50 against ...   \n",
       "3  Made best possible decision: IndiGo on barring...   \n",
       "4  India's biggest IPO of LIC subscribed nearly 3...   \n",
       "\n",
       "                                            original  \\\n",
       "0  The Indian rupee fell to an all-time low of 77...   \n",
       "1  Bitcoin fell on Monday to as low as $33,266 in...   \n",
       "2  The Indian rupee weakened further on Monday to...   \n",
       "3  IndiGo's CEO Ronojoy Dutta said the airline ma...   \n",
       "4  LIC's IPO, India's biggest IPO which opened on...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  indian rupee fell alltime low 7742 us dollar m...   \n",
       "1  bitcoin fell monday low 33266 morning trade ne...   \n",
       "2  indian rupee weakened monday close new alltime...   \n",
       "3  indigos ceo ronojoy dutta said airline made be...   \n",
       "4  lics ipo indias biggest ipo opened may 4 close...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  indian rupe fell alltim low 7742 us dollar mon...   \n",
       "1  bitcoin fell monday low 33266 morn trade near ...   \n",
       "2  indian rupe weaken monday close new alltim low...   \n",
       "3  indigo ceo ronojoy dutta said airlin made best...   \n",
       "4  lic ipo india biggest ipo open may 4 close may...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  indian rupee fell alltime low 7742 u dollar mo...  \n",
       "1  bitcoin fell monday low 33266 morning trade ne...  \n",
       "2  indian rupee weakened monday close new alltime...  \n",
       "3  indigo ceo ronojoy dutta said airline made bes...  \n",
       "4  lics ipo india biggest ipo opened may 4 closed...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above for news_df's content column.\n",
    "\n",
    "prep_article_data(news_df, 'original', extra_words = ['ha'], exclude_words = ['no']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9f4d1d9-145c-4ab0-8a6a-7c8adbb1ba80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learn to Code: Python Workshop on 4/23</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "      <td>according linkedin 1 promising job data scienc...</td>\n",
       "      <td>accord linkedin 1 promis job data scienc codeu...</td>\n",
       "      <td>according linkedin 1 promising job data scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coming Soon: Cloud Administration</td>\n",
       "      <td>We’re launching a new program out of San Anton...</td>\n",
       "      <td>launching new program san antonio acquisition ...</td>\n",
       "      <td>launch new program san antonio acquisit racksp...</td>\n",
       "      <td>launching new program san antonio acquisition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 Books Every Woman In Tech Should Read</td>\n",
       "      <td>On this International Women’s Day 2022 we want...</td>\n",
       "      <td>international womens day 2022 wanted tell stor...</td>\n",
       "      <td>thi intern women day 2022 want tell stori wome...</td>\n",
       "      <td>international woman day 2022 wanted tell story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "      <td>approach end january wanted look forward next ...</td>\n",
       "      <td>approach end januari want look forward next st...</td>\n",
       "      <td>approach end january wanted look forward next ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "      <td>happy announce vet tec benefits available used...</td>\n",
       "      <td>happi announc vet tec benefit avail use campu ...</td>\n",
       "      <td>happy announce vet tec benefit available used ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0             Learn to Code: Python Workshop on 4/23   \n",
       "1                  Coming Soon: Cloud Administration   \n",
       "2            5 Books Every Woman In Tech Should Read   \n",
       "3                  Codeup Start Dates for March 2022   \n",
       "4  VET TEC Funding Now Available For Dallas Veterans   \n",
       "\n",
       "                                            original  \\\n",
       "0  According to LinkedIn, the “#1 Most Promising ...   \n",
       "1  We’re launching a new program out of San Anton...   \n",
       "2  On this International Women’s Day 2022 we want...   \n",
       "3  As we approach the end of January we wanted to...   \n",
       "4  We are so happy to announce that VET TEC benef...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  according linkedin 1 promising job data scienc...   \n",
       "1  launching new program san antonio acquisition ...   \n",
       "2  international womens day 2022 wanted tell stor...   \n",
       "3  approach end january wanted look forward next ...   \n",
       "4  happy announce vet tec benefits available used...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  accord linkedin 1 promis job data scienc codeu...   \n",
       "1  launch new program san antonio acquisit racksp...   \n",
       "2  thi intern women day 2022 want tell stori wome...   \n",
       "3  approach end januari want look forward next st...   \n",
       "4  happi announc vet tec benefit avail use campu ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  according linkedin 1 promising job data scienc...  \n",
       "1  launching new program san antonio acquisition ...  \n",
       "2  international woman day 2022 wanted tell story...  \n",
       "3  approach end january wanted look forward next ...  \n",
       "4  happy announce vet tec benefit available used ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above for codeup_df's content column.\n",
    "\n",
    "prep_article_data(codeup_df, 'original', extra_words = ['ha'], exclude_words = ['no']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7145d-6a95-4cf7-8cb8-b0df69cd81ac",
   "metadata": {},
   "source": [
    "Ask yourself:\n",
    "\n",
    "If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
